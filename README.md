# üöÄ Pipeline de Big Data: Cassandra ‚Üí Spark ‚Üí ClickHouse

Este repositorio contiene la implementaci√≥n de un ecosistema de datos End-to-End dise√±ado para simular un entorno de producci√≥n masivo. El proyecto demuestra la orquestaci√≥n de una base de datos NoSQL (Cassandra), procesamiento distribuido (Apache Spark) y un Data Warehouse anal√≠tico (ClickHouse), todo integrado mediante Docker.

---

## üèóÔ∏è Arquitectura del Sistema

La arquitectura se basa en el modelo de tres capas para el manejo eficiente de Big Data:

1. **Capa de Ingesta (OLTP):** Apache Cassandra se encarga de recibir datos crudos (100,000 registros) con alta disponibilidad.
2. **Capa de Procesamiento (ELT):** Apache Spark (PySpark) realiza la lectura paralela, limpieza de datos y agregaciones complejas.
3. **Capa Anal√≠tica (OLAP):** ClickHouse almacena el resumen procesado, optimizado para consultas de Business Intelligence en milisegundos.

---

## üõ†Ô∏è Requisitos e Instalaci√≥n

### 1. Requisitos de Software

- **Docker Desktop** (con 4GB de RAM asignados como m√≠nimo).
- **Python 3.10+** (para ejecuci√≥n de scripts locales si es necesario).

### 2. Despliegue de Infraestructura

Desde la ra√≠z del proyecto, levanta los contenedores:
```bash
docker-compose up -d
```
**Nota:** Cassandra suele tardar unos 45 segundos en inicializar completamente sus protocolos de red.

### 3. Configuraci√≥n del Entorno Python

Instala las dependencias necesarias dentro de tu entorno de Jupyter o virtualenv:
```bash
pip install cassandra-driver clickhouse-connect pandas numpy
```

---

## üöÄ Gu√≠a de Ejecuci√≥n

### Fase 1 y 2: Ingesta en Cassandra

Se generan 100,000 registros sint√©ticos que simulan ventas minoristas.

**Comando de validaci√≥n:** Para verificar que los datos se cargaron correctamente en el cl√∫ster NoSQL:
```bash
docker exec -it cassandra_db cqlsh -e "SELECT COUNT(*) FROM proyecto_bigdata.ventas_crudas;"
```

### Fase 3: Procesamiento con PySpark

Se utiliza Spark para transformar el "Data Lake" (Cassandra) en informaci√≥n √∫til:

- **Limpieza:** Filtrado de registros inconsistentes (montos ‚â§ 0).
- **Agregaci√≥n:** Reducci√≥n de 100k registros a un resumen diario por categor√≠a.

### Fase 4: Carga al Data Warehouse (ClickHouse)

Los datos procesados se migran al esquema `dw_analitico`.

**Consultas Anal√≠ticas Finales:** Ejecuta estos comandos para obtener m√©tricas de negocio:

#### A. Top 10 categor√≠as (Volumen de ventas):
```bash
docker exec -it clickhouse_dw clickhouse-client -q "SELECT categoria, sum(ventas_totales) as total FROM dw_analitico.ventas_resumen GROUP BY categoria ORDER BY total DESC LIMIT 10;"
```

#### B. Promedio de ventas diarias por categor√≠a:
```bash
docker exec -it clickhouse_dw clickhouse-client -q "SELECT categoria, avg(ventas_totales) as promedio FROM dw_analitico.ventas_resumen GROUP BY categoria ORDER BY promedio DESC;"
```

---

## üìä An√°lisis de Rendimiento

Un punto clave de este proyecto es la comparativa de eficiencia:

- **Escritura (Cassandra):** Optimizada para la ingesta masiva de transacciones individuales.
- **Consulta (ClickHouse):** Gracias a su motor MergeTree y almacenamiento columnar, resuelve agregaciones (SUM/AVG) sobre miles de registros en una fracci√≥n del tiempo que tomar√≠a en una base de datos tradicional.

---

## ‚ö†Ô∏è Soluci√≥n de Problemas Comunes

- **Error de Conector Spark:** Si Spark no reconoce Cassandra, aseg√∫rate de que la sesi√≥n incluya el paquete: `com.datastax.spark:spark-cassandra-connector_2.12:3.5.0`.
  
- **Acceso Denegado en ClickHouse:** Si el usuario no tiene permisos para crear tablas o insertar, ejecuta este parche de seguridad en la terminal:
  ```bash
  docker exec -it clickhouse_dw bash -c "echo '<clickhouse><users><default><access_management>1</access_management></default></users></clickhouse>' > /etc/clickhouse-server/users.d/access.xml"
  docker restart clickhouse_dw
  ```

- **N√∫mero de Categor√≠as:** Si el reporte anal√≠tico solo muestra 5 categor√≠as, es el comportamiento esperado. El generador de datos utiliza un cat√°logo maestro de 5 categor√≠as (Hogar, Electr√≥nica, Ropa, Alimentos, Deportes).

- **Compatibilidad Python 3.13+:** El proyecto incluye un Mock del m√≥dulo asyncore para mantener la compatibilidad con el driver de Cassandra.

---

Proyecto desarrollado para la c√°tedra de Big Data - Universidad Nacional Experimental de Guayana (UNEG).
