# üöÄ Pipeline de Big Data: De Cassandra a ClickHouse (UNEG)

Este proyecto implementa un ecosistema de datos completo dise√±ado para manejar vol√∫menes masivos. Automatiza el flujo de **100,000 registros** desde un almacenamiento NoSQL de alta disponibilidad (**Cassandra**) hacia un motor OLAP optimizado para anal√≠tica (**ClickHouse**).

---

## üèóÔ∏è Arquitectura del Sistema

El pipeline sigue una arquitectura de tres capas dise√±ada para la eficiencia:

1. **Capa de Ingesta (Data Lake):** **Apache Cassandra** recibe datos at√≥micos (IDs, precios, fechas) simulando una base de datos transaccional de alta velocidad.
2. **Capa de Procesamiento (ETL):** Un motor de **Python + Pandas** (con parches de compatibilidad para Python 3.13) extrae, limpia y agrega los datos, transformando registros crudos en m√©tricas de negocio.
3. **Capa Anal√≠tica (Data Warehouse):** **ClickHouse** almacena los datos procesados, permitiendo consultas complejas y reportes gerenciales en milisegundos.

---

## üõ†Ô∏è Requisitos Previos

Antes de comenzar, aseg√∫rate de tener instalado:

1. **Docker Desktop:** Esencial para orquestar los contenedores de las bases de datos.
2. **Python 3.10+:** Lenguaje base del pipeline.
3. **Bibliotecas de Python:**
   ```bash
   pip install cassandra-driver clickhouse-connect pandas numpy
   ```

---

## üöÄ Configuraci√≥n y Ejecuci√≥n

### 1. Levantar Infraestructura

Desde la ra√≠z del proyecto, ejecuta:
```bash
docker-compose up -d
```
**Nota:** El contenedor de Cassandra puede tardar hasta 45 segundos en estar listo para recibir conexiones.

### 2. Ejecuci√≥n del Pipeline

Abre el archivo `Pipeline_BigData_UNEG.ipynb` y ejecuta las celdas en orden. El flujo realizar√°:

- Configuraci√≥n de seguridad y parches de compatibilidad.
- Creaci√≥n de esquemas en Cassandra y ClickHouse.
- Generaci√≥n e ingesta masiva de 100,000 registros.
- C√°lculo de agregaciones y carga en el Data Warehouse.

---

## üìä Validaci√≥n de Datos

Para verificar la integridad de los datos en cada etapa:

### A. Auditor√≠a en Cassandra (Datos Crudos)

Verifica que los registros individuales existan con el formato correcto:
```bash
docker exec -it cassandra_db cqlsh -e "SELECT * FROM proyecto_bigdata.ventas_crudas LIMIT 5;"
```

### B. Auditor√≠a en ClickHouse (Reporte Final)

Verifica los totales consolidados (Requiere credenciales configuradas):
```bash
docker exec -it clickhouse_dw clickhouse-client --user default --password 1234 -q "SELECT * FROM ventas_resumen FORMAT PrettyCompact;"
```

**Nota:** Estos comandos se ejecutan directamente en la terminal de tu sistema operativo (Windows/Linux/Mac), no dentro de Jupyter. Aseg√∫rate de que `docker-compose up` se haya ejecutado correctamente antes de probarlos.

---

## ‚ö†Ô∏è Notas de Implementaci√≥n (Soluci√≥n de Problemas)

- **Compatibilidad Python 3.13:** El proyecto incluye un "Mock" del m√≥dulo asyncore para evitar errores de importaci√≥n en el driver de Cassandra en versiones modernas de Python.
- **Seguridad:** ClickHouse est√° configurado con autenticaci√≥n (user: default, pass: 1234).
- **Memoria:** Si Docker falla al iniciar, aumenta el l√≠mite de RAM en Docker Desktop -> Settings -> Resources (Se recomiendan al menos 4GB).

Proyecto desarrollado para la c√°tedra de Big Data - UNEG.


üìù Actualizaci√≥n: Resoluci√≥n de la Fase 2 (Ingesta Masiva)
En esta etapa, se implement√≥ la generaci√≥n y carga de 100,000 registros en Apache Cassandra. Durante el desarrollo, se documentaron y resolvieron los siguientes puntos cr√≠ticos:

üõ†Ô∏è Soluci√≥n de Errores T√©cnicos
ModuleNotFoundError (cassandra-driver): Se identific√≥ que el entorno de Jupyter no contaba con el driver nativo. Se resolvi√≥ mediante la instalaci√≥n din√°mica dentro del notebook:

Python
!pip install cassandra-driver
UnresolvableContactPoints: Error de red donde Python no localizaba el contenedor. Se solucion√≥ asegurando que el host en la configuraci√≥n del cl√∫ster coincidiera con el nombre del servicio en docker-compose.yml (host: 'cassandra').

üì• Proceso de Ingesta

Generaci√≥n de Datos: Se utiliz√≥ la librer√≠a uuid, random y datetime para crear un dataset de 100,000 filas con categor√≠as como Electr√≥nica, Ropa y Hogar.


Optimizaci√≥n: Se utiliz√≥ session.prepare() para pre-compilar la consulta de inserci√≥n, mejorando significativamente la velocidad de carga.

Validaci√≥n T√©cnica: Se confirm√≥ la carga exitosa mediante el comando:

SQL
SELECT COUNT(*) FROM proyecto_bigdata.ventas_crudas;

‚öôÔ∏è Actualizaci√≥n: Resoluci√≥n de la Fase 3 (Procesamiento con Spark)

En esta fase se implement√≥ la capa de transformaci√≥n (ELT) para convertir 100,000 registros de datos crudos en m√©tricas de negocio √∫tiles.

üõ†Ô∏è Soluci√≥n de Errores T√©cnicos

Py4JJavaError: Se identific√≥ que Spark requer√≠a el conector oficial de Java para comunicarse con Cassandra. Se solucion√≥ forzando la descarga del paquete spark-cassandra-connector al iniciar la SparkSession.

Optimizaci√≥n de Lectura: Se configur√≥ el script para utilizar la Partition Key (fecha_venta) de Cassandra, permitiendo que Spark lea los datos de forma paralela y distribuida, evitando cuellos de botella.

üîÑ Transformaciones Realizadas (L√≥gica de Negocio)

Lectura Distribuida: Conexi√≥n exitosa al Keyspace proyecto_bigdata para cargar el DataFrame inicial.

Limpieza de Datos: Se aplic√≥ un filtro para eliminar registros inconsistentes (montos nulos o menores/iguales a cero), garantizando la integridad del an√°lisis.

Agregaci√≥n Paralela: Se procesaron los 100,000 registros para obtener:

Ventas totales por categor√≠a y fecha.
Conteo masivo de transacciones por periodo.
üìä Validaci√≥n
Se confirm√≥ la transformaci√≥n mediante la funci√≥n .show(), visualizando las m√©tricas consolidadas antes de su env√≠o al Data Warehouse.