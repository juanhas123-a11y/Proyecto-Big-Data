{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "136615e0-7f6b-435f-99f4-15752d634626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Sesi√≥n de Spark inicializada con el conector de Cassandra.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum, count, round\n",
    "\n",
    "# Detener sesiones previas para evitar conflictos de configuraci√≥n\n",
    "try:\n",
    "    spark.stop()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Inicializar sesi√≥n de Spark con el conector de Cassandra\n",
    "# Usamos el paquete oficial de Datastax para asegurar compatibilidad\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Pipeline_BigData_Fase3\") \\\n",
    "    .config(\"spark.jars.packages\", \"com.datastax.spark:spark-cassandra-connector_2.12:3.5.0\") \\\n",
    "    .config(\"spark.cassandra.connection.host\", \"cassandra_db\") \\\n",
    "    .config(\"spark.cassandra.connection.port\", \"9042\") \\\n",
    "    .config(\"spark.sql.extensions\", \"com.datastax.spark.connector.CassandraSparkExtensions\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"‚úÖ Sesi√≥n de Spark inicializada con el conector de Cassandra.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81e43af2-dd80-493c-8dad-640241b0f7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Resumen anal√≠tico generado (Vista previa):\n",
      "+-----------+-----------+--------------+----------------------+\n",
      "|fecha_venta|  categoria|ventas_totales|cantidad_transacciones|\n",
      "+-----------+-----------+--------------+----------------------+\n",
      "| 2026-01-02|  Alimentos|     146229.09|                   306|\n",
      "| 2026-02-03|  Alimentos|     178272.22|                   348|\n",
      "| 2026-01-29|      Hogar|     158353.48|                   315|\n",
      "| 2025-12-10|       Ropa|     170576.94|                   353|\n",
      "| 2026-02-02|Electr√≥nica|     178215.53|                   364|\n",
      "| 2025-12-12|Electr√≥nica|     169096.27|                   331|\n",
      "| 2026-01-19|   Deportes|     182792.73|                   366|\n",
      "| 2026-01-01|       Ropa|      165066.2|                   345|\n",
      "| 2026-02-05|  Alimentos|     174772.16|                   324|\n",
      "| 2026-01-09|      Hogar|     169140.95|                   330|\n",
      "+-----------+-----------+--------------+----------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "root\n",
      " |-- fecha_venta: date (nullable = true)\n",
      " |-- categoria: string (nullable = true)\n",
      " |-- ventas_totales: double (nullable = true)\n",
      " |-- cantidad_transacciones: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fase 3.1: Lectura distribuida desde el Keyspace de Cassandra\n",
    "df_crudo = spark.read \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .options(table=\"ventas_crudas\", keyspace=\"proyecto_bigdata\") \\\n",
    "    .load()\n",
    "\n",
    "# Fase 3.3: Limpieza de datos (eliminaci√≥n de montos inv√°lidos)\n",
    "df_limpio = df_crudo.filter(col(\"monto_total\") > 0)\n",
    "\n",
    "# Fase 3.2: L√≥gica de Agregaci√≥n\n",
    "# Consolidamos 100k registros en un resumen diario por categor√≠a\n",
    "df_resumen = df_limpio.groupBy(\"fecha_venta\", \"categoria\") \\\n",
    "    .agg(\n",
    "        round(sum(\"monto_total\"), 2).alias(\"ventas_totales\"),\n",
    "        count(\"id_venta\").alias(\"cantidad_transacciones\")\n",
    "    )\n",
    "\n",
    "print(\"üìä Resumen anal√≠tico generado (Vista previa):\")\n",
    "df_resumen.show(10)\n",
    "df_resumen.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40aab025-b5ea-4c6e-b425-f93a7384eba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: clickhouse-connect in /opt/conda/lib/python3.11/site-packages (0.10.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from clickhouse-connect) (2023.7.22)\n",
      "Requirement already satisfied: urllib3>=1.26 in /opt/conda/lib/python3.11/site-packages (from clickhouse-connect) (2.0.7)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.11/site-packages (from clickhouse-connect) (2023.3.post1)\n",
      "Requirement already satisfied: zstandard in /opt/conda/lib/python3.11/site-packages (from clickhouse-connect) (0.21.0)\n",
      "Requirement already satisfied: lz4 in /opt/conda/lib/python3.11/site-packages (from clickhouse-connect) (4.3.2)\n"
     ]
    }
   ],
   "source": [
    "# Instalaci√≥n de cliente ligero para ClickHouse (v√≠a protocolo HTTP)\n",
    "!pip install clickhouse-connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "695ca0b4-9e76-4399-baba-b8e9a4b87fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Preparando registros para la migraci√≥n al Data Warehouse...\n",
      "‚úÖ CARGA EXITOSA: 300 registros sincronizados con dw_analitico.\n",
      "üöÄ Pipeline de integraci√≥n finalizado: Cassandra -> Spark -> ClickHouse.\n"
     ]
    }
   ],
   "source": [
    "import clickhouse_connect\n",
    "\n",
    "# 1. Preparaci√≥n de datos desde Spark\n",
    "print(\"üì¶ Preparando registros para la migraci√≥n al Data Warehouse...\")\n",
    "registros = [list(row) for row in df_resumen.collect()]\n",
    "\n",
    "# 2. Configuraci√≥n y Carga en ClickHouse\n",
    "try:\n",
    "    # Conexi√≥n utilizando el Service Name de la red Docker\n",
    "    client = clickhouse_connect.get_client(\n",
    "        host='clickhouse_dw', \n",
    "        port=8123, \n",
    "        username='default', \n",
    "        password=''\n",
    "    )\n",
    "\n",
    "    # Inicializaci√≥n del entorno anal√≠tico (DW)\n",
    "    client.command(\"CREATE DATABASE IF NOT EXISTS dw_analitico\")\n",
    "    \n",
    "    # Definici√≥n de la tabla optimizada para an√°lisis (Motor MergeTree)\n",
    "    client.command(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS dw_analitico.ventas_resumen (\n",
    "            fecha_venta Date,\n",
    "            categoria String,\n",
    "            ventas_totales Float64,\n",
    "            cantidad_transacciones Int64\n",
    "        ) ENGINE = MergeTree() \n",
    "        ORDER BY (fecha_venta, categoria)\n",
    "    \"\"\")\n",
    "\n",
    "    # Inserci√≥n at√≥mica de los datos procesados\n",
    "    client.insert(\n",
    "        'dw_analitico.ventas_resumen', \n",
    "        registros, \n",
    "        column_names=['fecha_venta', 'categoria', 'ventas_totales', 'cantidad_transacciones']\n",
    "    )\n",
    "\n",
    "    print(f\"‚úÖ CARGA EXITOSA: {len(registros)} registros sincronizados con dw_analitico.\")\n",
    "    print(\"üöÄ Pipeline de integraci√≥n finalizado: Cassandra -> Spark -> ClickHouse.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error en la sincronizaci√≥n del Data Warehouse: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8357e5a3-9125-43ec-83c1-ea0a247df8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä EJECUTANDO CONSULTAS ANAL√çTICAS EN CLICKHOUSE\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3 style='color: #1565c0;'>1. Ranking de Ingresos por Categor√≠a</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_1eaa8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1eaa8_level0_col0\" class=\"col_heading level0 col0\" >Categor√≠a</th>\n",
       "      <th id=\"T_1eaa8_level0_col1\" class=\"col_heading level0 col1\" >Ingresos Totales</th>\n",
       "      <th id=\"T_1eaa8_level0_col2\" class=\"col_heading level0 col2\" >Transacciones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1eaa8_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_1eaa8_row0_col0\" class=\"data row0 col0\" >Electr√≥nica</td>\n",
       "      <td id=\"T_1eaa8_row0_col1\" class=\"data row0 col1\" >$40,436,638.07</td>\n",
       "      <td id=\"T_1eaa8_row0_col2\" class=\"data row0 col2\" >80,227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1eaa8_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_1eaa8_row1_col0\" class=\"data row1 col0\" >Hogar</td>\n",
       "      <td id=\"T_1eaa8_row1_col1\" class=\"data row1 col1\" >$40,386,488.12</td>\n",
       "      <td id=\"T_1eaa8_row1_col2\" class=\"data row1 col2\" >80,284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1eaa8_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_1eaa8_row2_col0\" class=\"data row2 col0\" >Alimentos</td>\n",
       "      <td id=\"T_1eaa8_row2_col1\" class=\"data row2 col1\" >$40,283,932.62</td>\n",
       "      <td id=\"T_1eaa8_row2_col2\" class=\"data row2 col2\" >80,193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1eaa8_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_1eaa8_row3_col0\" class=\"data row3 col0\" >Ropa</td>\n",
       "      <td id=\"T_1eaa8_row3_col1\" class=\"data row3 col1\" >$40,258,995.59</td>\n",
       "      <td id=\"T_1eaa8_row3_col2\" class=\"data row3 col2\" >80,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1eaa8_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_1eaa8_row4_col0\" class=\"data row4 col0\" >Deportes</td>\n",
       "      <td id=\"T_1eaa8_row4_col1\" class=\"data row4 col1\" >$39,783,281.57</td>\n",
       "      <td id=\"T_1eaa8_row4_col2\" class=\"data row4 col2\" >79,196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x762a7300e8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3 style='color: #2e7d32;'>2. Promedio de Venta por Transacci√≥n</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_f2f3b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f2f3b_level0_col0\" class=\"col_heading level0 col0\" >Categor√≠a</th>\n",
       "      <th id=\"T_f2f3b_level0_col1\" class=\"col_heading level0 col1\" >Ticket Promedio ($)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f2f3b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f2f3b_row0_col0\" class=\"data row0 col0\" >Electr√≥nica</td>\n",
       "      <td id=\"T_f2f3b_row0_col1\" class=\"data row0 col1\" >$504.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2f3b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f2f3b_row1_col0\" class=\"data row1 col0\" >Ropa</td>\n",
       "      <td id=\"T_f2f3b_row1_col1\" class=\"data row1 col1\" >$503.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2f3b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f2f3b_row2_col0\" class=\"data row2 col0\" >Hogar</td>\n",
       "      <td id=\"T_f2f3b_row2_col1\" class=\"data row2 col1\" >$502.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2f3b_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f2f3b_row3_col0\" class=\"data row3 col0\" >Alimentos</td>\n",
       "      <td id=\"T_f2f3b_row3_col1\" class=\"data row3 col1\" >$502.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2f3b_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f2f3b_row4_col0\" class=\"data row4 col0\" >Deportes</td>\n",
       "      <td id=\"T_f2f3b_row4_col1\" class=\"data row4 col1\" >$502.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x762a72ef4a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import clickhouse_connect\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Conexi√≥n al Data Warehouse\n",
    "client = clickhouse_connect.get_client(host='clickhouse_dw', port=8123, username='default', password='')\n",
    "\n",
    "print(\"üìä EJECUTANDO CONSULTAS ANAL√çTICAS EN CLICKHOUSE\\n\")\n",
    "\n",
    "# --- CONSULTA 1: An√°lisis de Desempe√±o por Categor√≠a (Agregaci√≥n Global) ---\n",
    "# Cassandra no puede sumar todos los montos de la tabla sin un ALLOW FILTERING (muy lento)\n",
    "query_1 = '''\n",
    "    SELECT \n",
    "        categoria, \n",
    "        sum(ventas_totales) AS ingresos_totales,\n",
    "        sum(cantidad_transacciones) AS total_operaciones\n",
    "    FROM dw_analitico.ventas_resumen\n",
    "    GROUP BY categoria\n",
    "    ORDER BY ingresos_totales DESC\n",
    "'''\n",
    "\n",
    "# --- CONSULTA 2: Promedio de Ticket de Venta por Categor√≠a ---\n",
    "# ClickHouse calcula promedios sobre millones de registros al instante\n",
    "query_2 = '''\n",
    "    SELECT \n",
    "        categoria, \n",
    "        avg(ventas_totales / cantidad_transacciones) AS ticket_promedio\n",
    "    FROM dw_analitico.ventas_resumen\n",
    "    GROUP BY categoria\n",
    "    ORDER BY ticket_promedio DESC\n",
    "'''\n",
    "\n",
    "try:\n",
    "    # Ejecutar y mostrar Consulta 1\n",
    "    res1 = client.query(query_1)\n",
    "    df1 = pd.DataFrame(res1.result_rows, columns=['Categor√≠a', 'Ingresos Totales', 'Transacciones'])\n",
    "    display(HTML(\"<h3 style='color: #1565c0;'>1. Ranking de Ingresos por Categor√≠a</h3>\"))\n",
    "    display(df1.style.format({'Ingresos Totales': '${:,.2f}', 'Transacciones': '{:,}'}))\n",
    "\n",
    "    # Ejecutar y mostrar Consulta 2\n",
    "    res2 = client.query(query_2)\n",
    "    df2 = pd.DataFrame(res2.result_rows, columns=['Categor√≠a', 'Ticket Promedio ($)'])\n",
    "    display(HTML(\"<h3 style='color: #2e7d32;'>2. Promedio de Venta por Transacci√≥n</h3>\"))\n",
    "    display(df2.style.format({'Ticket Promedio ($)': '${:,.2f}'}))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error al ejecutar las consultas: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7689d75d-e338-411c-b5a3-429ee7e17810",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
